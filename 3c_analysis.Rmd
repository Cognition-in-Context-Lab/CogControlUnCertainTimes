---
title: "3C Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Packages
library("ggpubr")
library(psych)
library(tidyverse)
library(ggplot2)
#library(dplyr)
#library(plyr)
```
# PROCESSING and PRE-ANALYSIS SECTION # 

## Load and Cleanup Data
```{r}
df <- read.csv("3C_Live_Study_Data.csv", header=T, na.strings="")

#442 total participants 
#413 participants completed the entire study, 29 did not. 

## Drop unneeded rows (pilot data, incomplete trials, remove entries that are shorter than 6 mins longer than 60 minutes) & cols
unneeded_cols <- c("StartDate", "EndDate", "Status", "IPAddress", "Progress", "Finished", "RecordedDate", "ResponseId", "RecipientLastName", "RecipientFirstName", "RecipientEmail", "ExternalReference", "LocationLatitude", "LocationLongitude", "DistributionChannel", "UserLanguage", "Gender_4_TEXT...Parent.Topics", "Gender_4_TEXT...Sentiment.Polarity", "Gender_4_TEXT...Sentiment.Score", "Gender_4_TEXT...Sentiment", "Gender_4_TEXT...Topics", "Gender_4_TEXT...Topic.Sentiment.Label", "Gender_4_TEXT...Topic.Sentiment.Score")

# Return entries where duration was longer than 45 min.
df$'Duration..in.seconds.' = as.numeric(as.character(df$'Duration..in.seconds.'))
df[which(df$'Duration..in.seconds.' >= 45*60), ]  # 4 entries, 394, 410, 415, and 444. 410 = 31 seconds over limit, so not going to exclude. 

# return entries where duration was shorter than 6 mins.
df$'Duration..in.seconds.' = as.numeric(as.character(df$'Duration..in.seconds.'))
df[which(df$'Duration..in.seconds.' <= 360), ]   # 29 entries, 8,9,10, 11, 12, 14, 22, 205, 222, 255, 324, 416, 417, 418, 419, 420, 421, 423, 424, 426, 429, 432, 433, 434, 436, 439, 443

# remove Gender and Race open response columns to be able to remove rows with missing values
NAcols <- c("Gender_4_TEXT", "Race_6_TEXT")

# Exclude folks who took longer than 45 mins or were shorter than 6 mins, un-needed columns, and DoG and Pandemic Expextation outliers (see lines 145 for exclusion criteria calcuations. DoG and Expextation Outliers removed here because of not able to do it below. )

#exclude remaining folks progress less than 100 percent 

df[which(df$'Progress' <= 100), ]

# Remove all the folks who meet the criteria stated above 

df <- df[-c(1,2,8:12,14,22,23,118,176,191,205,222,255,243,252,270,323,324,331,350,364,392,394,415:444,423,424,426,426,429,432:434,436,439,443,444), ]

df <- df[ , !names(df) %in% unneeded_cols]
df <- df[ , !names(df) %in% NAcols]

#388 participants are now left out of the original 442

```

## Creating COVID19 DoG Index 
# Andrew/Kate decided placement should be above removing NAs, not working in reverse order
#Add columns with time frames in days

```{r}
# saving both response in set of units (days-years), (.2_x) AND numbers (0-30), (.1_x)
dog1 <- list("COVID_DoG_Questions.1", df$COVID_DoG_Questions.2_1, df$COVID_DoG_Questions.1_1)
dog2 <- list("COVID_DoG_Questions.2", df$COVID_DoG_Questions.2_2, df$COVID_DoG_Questions.1_2)
dog3 <- list("COVID_DoG_Questions.3", df$COVID_DoG_Questions.2_3, df$COVID_DoG_Questions.1_3)
dog4 <- list("COVID_DoG_Questions.4", df$COVID_DoG_Questions.2_4, df$COVID_DoG_Questions.1_4)
dog5 <- list("COVID_DoG_Questions.5", df$COVID_DoG_Questions.2_5, df$COVID_DoG_Questions.1_5)
dog6 <- list("COVID_DoG_Questions.6", df$COVID_DoG_Questions.2_6, df$COVID_DoG_Questions.1_6)

# saving both response in set of units (days-years), (.1_x) AND numbers (0-30), (.2_x)
pandemic_len <- list("PandemicLengthExpect.1", df$PandemicLengthExpect.1_1, df$PandemicLengthExpect.2_1)

## create function called create_columns that takes in UNITS and NUMBERS
# depending on units, multiplies NUMBERS by correct converstion to have units ALL in days
# e.g. 2 = weeks, so NUMBER (len_col) x 7 = days 
# fixed from (units_col, 1, 1) to (units_col, 1, 2) because NUMBERS that were more than 1 digit (e.g. 11, 13) were being cut off 
# so 11 months was being converted to 30 days not 330 days
create_columns <- function(units_col, len_col) {
  case_when(as.numeric(substring(units_col, 1, 2)) == 1 ~ as.numeric(substring(len_col, 1, 2)) * 1,
            as.numeric(substring(units_col, 1, 2)) == 2 ~ as.numeric(substring(len_col, 1, 2)) * 7,
            as.numeric(substring(units_col, 1, 2)) == 3 ~ as.numeric(substring(len_col, 1, 2)) * 30,
            as.numeric(substring(units_col, 1, 2)) == 4 ~ as.numeric(substring(len_col, 1, 2)) * 365)
}

## work to debug create_columns function
# test each of the functions in create_columns
#units_col = 12
#units <- substring(units_col, 1, 1)
#units
# prints out 1 when should print out 12
# function not taking the entire number (13)
#solution: change as.numeric(substring((units_col, 1, 1)) to (units_col, 1, 2)))

# loop through 6 categories saved above and apply function
# A NOTE: I added the dplyr function before mutate because when you load in packages that include the mutate function, it overwrites the function in dplyr and the new columns won't show up in the df dataframe, THUS specifiying the mutate function from the dplyr package 
df <- df %>% dplyr::mutate(!!dog1[[1]] := create_columns(dog1[[2]], dog1[[3]]),
              !!dog2[[1]] := create_columns(dog2[[2]], dog2[[3]]),
              !!dog3[[1]] := create_columns(dog3[[2]], dog3[[3]]),
              !!dog4[[1]] := create_columns(dog4[[2]], dog4[[3]]),
              !!dog5[[1]] := create_columns(dog5[[2]], dog5[[3]]),
              !!dog6[[1]] := create_columns(dog6[[2]], dog6[[3]]),
              !!pandemic_len[[1]] := create_columns(pandemic_len[[2]], pandemic_len[[3]]),
              .before = SocialNorms_Family_1
              )
view(df)

#checks: are lengths the same?
#length(pandemic_len[[2]])
#length(pandemic_len[[3]])
#df %>% select(PandemicLengthExpect.1_1, PandemicLengthExpect.2_1, PandemicLengthExpect.1)

#view(df)
```

## Remove missing values and convert classes
```{r}
#check where the missing values are
#rowSums(is.na(df))

#remove missing values
##show where missing values are
df[!complete.cases(df), ]   #6 entries
##create new dataset with no missing values
omit_df <- na.omit(df)
nrow(omit_df) #391
#view(omit_df)
sum(is.na(omit_df))

#convert character values (except Nationality and Occupation) to numeric to be able to calculate stats
numeric_cols1 <- names(omit_df)[3:206] #ends on Race 
numeric_cols2 <- names(omit_df)[208] #education
numeric_cols3 <- names(omit_df)[210:224] #begins on Measure2_2 to end of columns

#view(omit_df)

omit_df[numeric_cols1] <- lapply(omit_df[numeric_cols1], as.numeric)
omit_df[numeric_cols2] <- lapply(omit_df[numeric_cols2], as.numeric)
omit_df[numeric_cols3] <- lapply(omit_df[numeric_cols3], as.numeric)

sapply(omit_df, class) # all numeric!

#view(omit_df)

#check that everyone included in omit_df passed both attention checks
omit_df$attentioncheck_1 #all 4s
omit_df$attentioncheck_2 #all 3s

# recode value in Age variable that participant entered their birth year (1971) instead of their age
which(omit_df == 1971, arr.ind=TRUE)
# row = 232, col = 202
omit_df[232,202] <- 2021-1971
omit_df[232,202]

```

## COVID DoG and Pandemic Expextation Processing 
# COVID DoG Indice 
```{r}
mini_df <- omit_df %>% select(COVID_DoG_Questions.1:COVID_DoG_Questions.6)
omit_df <- omit_df %>% mutate(COVID_DoG_Sum = rowSums(mini_df), .before = PandemicLengthExpect.1)
summary(omit_df$COVID_DoG_Sum)

# make index of delaying across all 6 questions (average delaying across categories)
omit_df <- omit_df %>% mutate(COVID_DoG_index = rowMeans(mini_df), 
                              .before = PandemicLengthExpect.1)

#create 1 index across social situations/gatherings
mini_df <- omit_df %>% select(COVID_DoG_Questions.1:COVID_DoG_Questions.3)
omit_df <- omit_df %>% mutate(socialgatherings_index = rowMeans(mini_df),
                              .before = PandemicLengthExpect.1)
#create 1 index across traveling
mini_df <- omit_df %>% select(COVID_DoG_Questions.4:COVID_DoG_Questions.6)
omit_df <- omit_df %>% mutate(traveling_index = rowMeans(mini_df), 
                              .before = PandemicLengthExpect.1)

#view(omit_df)

```

# COVID DoG and Pandemic Expextation Outlier Exclusions 
```{r}

# COVID DoG Indice SD = 363.78

## 3 Standard Devations above COVID DoG Indice mean calculation 

341.94 + 363.78 + 363.78 +363.78 

## Exclusion of participants 3SD above COVID DoG Indice

omit_df[which(omit_df$'COVID_DoG_index' >=  1433.28), ] #returns 7

# Pandemic Expectation SD = 930.63

## 3 Standard Deviations above mean calculation 

694.66 + 930.63 + 930.63 + 930.63

## Exclusion of participants 3SD above Pandemic Expectation Indice

omit_df[which(omit_df$'PandemicLengthExpect.1' >=  3486.55), ] #returns 5

#See line 44 for exclusions
```

# Attempt to normalize COVID DoG and Pandemic Length Expextation Data 
```{r}

# Plot for COVID DoG index (average delaying across 6 scenarios for each participant)
hist(omit_df$COVID_DoG_index)

# Plot for Pandemic Length Expectation (average pandemic length expectation for each participant)
hist(omit_df$PandemicLengthExpect.1)

# Log transformation of COVID DoG Index 

omit_df$logCOVID_DoG_index=log(omit_df$COVID_DoG_index)

hist(omit_df$logCOVID_DoG_index)

#a lot of the data is centered around a couple bars, what does it look like if we make more bars?

hist(omit_df$logCOVID_DoG_index, breaks = 50)


# Log transformation of Pandemic Length Expextation

omit_df$logPandemicLengthExpect.1=log(omit_df$PandemicLengthExpect.1)

hist(omit_df$logPandemicLengthExpect.1) 

#a lot of the data is centered around a couple bars, what does it look like if we make more bars?

hist(omit_df$logPandemicLengthExpect.1, breaks = 50) 



```

## Remaining Task Indicies 

# MCQ (specfic analysis)
```{r}
```

# Perceived COVID DoG Risk and Value
```{r}
mini_df <- omit_df %>% select(PerceivedRisk_1:PerceivedRisk_6)
omit_df <- omit_df %>% mutate(Perceived_Risk_Sum = rowSums(mini_df), 
                              .before = PerceivedValue_1)
omit_df <- omit_df %>% mutate(PerceivedRisk_index = rowMeans(mini_df),
                              .before = PerceivedValue_1)

mini_df <- omit_df %>% select(PerceivedValue_1:PerceivedValue_6)
omit_df <- omit_df %>% mutate(Perceived_Value_Sum = rowSums(mini_df),
                              .before = GCS_1)
omit_df <- omit_df %>% mutate(PercevedValue_index = rowMeans(mini_df), 
                              .before = GCS_1)

```

# Social Norms (Mean)
```{r}

# Social Norm Index across three factors   

mini_df <- omit_df %>% select(SocialNorms_Family_1:SocialNorms_Stranger_3)
omit_df <- omit_df %>% mutate(Norms_index = rowMeans(mini_df),
                              .before = PerceivedRisk_1)
#family norms index

mini_df <- omit_df %>% select(SocialNorms_Family_1:SocialNorms_Family_3)
omit_df <- omit_df %>% mutate(FamilyNorm_index = rowMeans(mini_df), 
                              .before = PerceivedRisk_1)

#friends norm index

mini_df <- omit_df %>% select(SocialNorms_Friends_1:SocialNorms_Friends_3)
omit_df <- omit_df %>% mutate(FriendsNorm_index = rowMeans(mini_df), 
                              .before = PerceivedRisk_1)

#strangers norm index
mini_df <- omit_df %>% select(SocialNorms_Stranger_1:SocialNorms_Stranger_3)
omit_df <- omit_df %>% mutate(StrangerNorm_index = rowMeans(mini_df), 
                              .before = PerceivedRisk_1)

```

# General Confidence (sum score)
```{r}

#re-coding reverse coded variables
mini_df <- omit_df %>% select(GCS_5)
omit_df <- omit_df %>% mutate(GCS_5 = 7 - GCS_5)

mini_df <- omit_df %>% select(contains("GCS"))
omit_df <- omit_df %>% mutate(GCS_index = rowMeans(mini_df),
                              .before = IUS_1)

```

# Intolerance of Uncertainty (sum score, 3 indices)
```{r}
mini_df <- omit_df %>% select(IUS_1:IUS_12)
omit_df <- omit_df %>% mutate(IUS_Sum = rowSums(mini_df), 
                              .before = MFQpart1_1)

mini_df <- omit_df %>% select(IUS_1:IUS_7)
omit_df <- omit_df %>% mutate(IUS_ProspectiveAnexity_index = rowSums(mini_df),
                              .before = MFQpart1_1)

mini_df <- omit_df %>% select(IUS_8:IUS_12)
omit_df <- omit_df %>% mutate(IUS_inhibitory_anexity_index = rowSums(mini_df),
                              .before = MFQpart1_1)

```

# Political Orientation ( Measure 2 with means for each predictor, Measure 5 with means across the two factors)
```{r}
# measure 2 indices
mini_df <- omit_df %>% select(Measure2_2)
omit_df <- omit_df %>% mutate(Measure2_lib_Index = rowMeans(mini_df), 
                              .before = Measure5_1)
mini_df <- omit_df %>% select(Measure2_3)
omit_df <- omit_df %>% mutate(Measure2_cons_Index = rowMeans(mini_df), 
                              .before = Measure5_1)
mini_df <- omit_df %>% select(Measure2_4)
omit_df <- omit_df %>% mutate(Measure2_lib_Index = rowMeans(mini_df), 
                              .before = Measure5_1)

# measure 5 indices

#re-coding reverse coded variables
mini_df <- omit_df %>% select(Measure5_1, Measure5_7)
omit_df <- omit_df %>% mutate(Measure5_1 = 100 - Measure5_1)
omit_df <- omit_df %>% mutate(Measure5_7 = 100 - Measure5_7)

#indice across both scales

mini_df <- omit_df %>% select(Measure5_1:Measure5_14)
omit_df <- omit_df %>% mutate(Measure5_SECS_Index = rowMeans(mini_df), 
                              .before = logCOVID_DoG_index)
#social indice

mini_df <- omit_df %>% select(Measure5_1,Measure5_5, Measure5_6, Measure5_9, Measure5_10, Measure5_13, Measure5_14)
omit_df <- omit_df %>% mutate(Measure5_Social_Index = rowMeans(mini_df), 
                              .before = logCOVID_DoG_index)

#political indice

mini_df <- omit_df %>% select(Measure5_4, Measure5_7, Measure5_8, Measure5_11, Measure5_12)
omit_df <- omit_df %>% mutate(Measure5_Political_Index = rowMeans(mini_df), 
                              .before = logCOVID_DoG_index)

```

# MFQ (5 Factor Index)
```{r}

#harm foundation MFQpart1_1,MFQpart1_7, MFQpart1_12, MFQpart2_1, MFQpart2_7, MFQpart2_12

mini_df <- omit_df %>% select(MFQpart1_1,MFQpart1_7, MFQpart1_12, MFQ_part2_1, MFQ_part2_7, MFQ_part2_12)
omit_df <- omit_df %>% mutate(harm_foundation = rowMeans(mini_df), 
                              .before = Disgust_1)

#fairness foundation MFQpart1_2, MFQpart1_8, MFQpart1_13, MFQpart2_2, MFQpart2_8, MFQpart2_13

mini_df <- omit_df %>% select(MFQpart1_2, MFQpart1_8, MFQpart1_13, MFQ_part2_2, MFQ_part2_8, MFQ_part2_13)
omit_df <- omit_df %>% mutate(fairness_foundation = rowMeans(mini_df), 
                              .before = Disgust_1)

#ingroup foundation MFQpart1_3, MFQpart1_9, MFQpart1_14, MFQpart2_3, MFQpart2_9, MFQpart2_14

mini_df <- omit_df %>% select(MFQpart1_3, MFQpart1_9, MFQpart1_14, MFQ_part2_3, MFQ_part2_9, MFQ_part2_14)
omit_df <- omit_df %>% mutate(ingroup_foundation = rowMeans(mini_df), 
                              .before = Disgust_1)

#authoirty foundation MFQpart1_4, MFQpart1_10, MFQpart1_15, MFQpart2_4, MFQpart2_10, MFQpart2_15

mini_df <- omit_df %>% select(MFQpart1_4, MFQpart1_10, MFQpart1_15, MFQ_part2_4, MFQ_part2_10, MFQ_part2_15)
omit_df <- omit_df %>% mutate(authority_foundation = rowMeans(mini_df), 
                              .before = Disgust_1)

#purity foundation MFQpart1_5, MFQpart1_11, MFQpart1_16, MFQpart2_16, MFQpart2_11, MFQpart2_5

mini_df <- omit_df %>% select(MFQpart1_5, MFQpart1_11, MFQpart1_16, MFQ_part2_16, MFQ_part2_11, MFQ_part2_5)
omit_df <- omit_df %>% mutate(purity_foundation = rowMeans(mini_df), 
                              .before = Disgust_1)

```

# COVID Stress (Mean across all five portions and five seperate)
```{r}
#Stress Scale Main Indice 

mini_df <- omit_df %>% select(contains("Worries") | contains("Problems") | contains("Checking"))
omit_df <- omit_df %>% mutate(Stress_index = rowMeans(mini_df),
                              .before = Impacts_financial1)
#Stress Scale, Sub Indice COVID danger and contamination fears

mini_df <- omit_df %>% select(Worries_1:Worries_6)
omit_df <- omit_df %>% mutate(COVIDDanger_ContFears_index = rowMeans(mini_df),
                              .before = Impacts_financial1)
#Stress Scale, Sub Indice COVID fears about economic consequences

mini_df <- omit_df %>% select(Worries_7:Worries_12)
omit_df <- omit_df %>% mutate(COVID_econ_fears_index = rowMeans(mini_df),
                              .before = Impacts_financial1)
#Stress Scale, Sub Indice COVID xenophobia

mini_df <- omit_df %>% select(Worries_13:Worries_18)
omit_df <- omit_df %>% mutate(COVID_xenophobia = rowMeans(mini_df),
                              .before = Impacts_financial1)

#Stress Scale, Sub indice COVID compulsive checking and reassurance seeking 

mini_df <- omit_df %>% select(Worries_19:Worries_24,CheckingBeh_1:CheckingBeh_6)
omit_df <- omit_df %>% mutate(COVID_checking = rowMeans(mini_df),
                              .before = Impacts_financial1)

#Stress Scale, Sub Indice COVID traumatic stress symptoms
mini_df <- omit_df %>% select(Problems_1:Problems_6)
omit_df <- omit_df %>% mutate(COVID_traumatic_stress = rowMeans(mini_df),
                              .before = Impacts_financial1)
                              
```

# COVID Impacts and Experiences (Ipmacts calculated as a mean, Expereinces TBD)
```{r}
Impacts <- omit_df %>% select(Impacts_financial1:Impacts_psychology3)
Experiences <- omit_df %>% select(contains("PersonalDiagnoses") | contains("Proximity") | contains("News"))
omit_df <- omit_df %>% mutate(Impacts_index = rowMeans(Impacts), 
                              .before = PersonalDiagnoses_1)
omit_df <- omit_df %>% mutate(Experiences_index = rowMeans(Experiences),
                              .before = Age)
```

# Disgust (Mean Index across three sub indice)
```{r}
#Pathogen Indice 

mini_df <- omit_df %>% select(Disgust_3, Disgust_6, Disgust_9, Disgust_12, Disgust_15, Disgust_18, Disgust_21)
omit_df <- omit_df %>% mutate(Pathogen_Disgust_index = rowMeans(mini_df), 
                              .before = SDRS.5_Q1)

#Sexual Indice 

mini_df <- omit_df %>% select(Disgust_2, Disgust_5, Disgust_8, Disgust_11, Disgust_14, Disgust_17, Disgust_20)
omit_df <- omit_df %>% mutate(Sexual_Disgust_index = rowMeans(mini_df), 
                              .before = SDRS.5_Q1)

#Moral Indice 

mini_df <- omit_df %>% select(Disgust_1, Disgust_4, Disgust_7, Disgust_10, Disgust_13, Disgust_16, Disgust_19 )
omit_df <- omit_df %>% mutate(Moral_Disgust_index = rowMeans(mini_df), 
                              .before = SDRS.5_Q1)
```

# Social Desirability (transformed sum)
```{r}
mini_df <- omit_df %>% select(SDRS.5_Q1:SDRS.5_Q5)
omit_df <- omit_df %>% mutate(SDRS_Sum = rowSums(mini_df), 
                              .before = Worries_1)

#view(omit_df)
```

# ANALYSIS SECTION #

## Summary statistics ##
```{r}
summary(omit_df$PandemicLengthExpect.1)
describe(omit_df$COVID_DoG_Sum)
describe(omit_df$COVID_DoG_index)
describe(omit_df$MCQ_Sum)
#describe(omit_df$Norms_Sum)
describe(omit_df$GCS_Sum)
describe(omit_df$IUS_Sum)
describe(omit_df$MFQ_sum_part1)
describe(omit_df$MFQ_sum_part2)
describe(omit_df$MFQ_total_sum)
describe(omit_df$Disgust_Sum)
describe(omit_df$Perceived_Value_Sum)
describe(omit_df$SDRS_Sum)
describe(omit_df$Impacts_sum)
describe(omit_df$Experiences_sum)
describe(omit_df$Stress_Sum)
describe(omit_df$MFQ_total_sum)
describe(omit_df$Measure2_PO_Sum)
describe(omit_df$Measure5_PO_Sum)
describe(omit_df$PO_Total_Sum)
describe(omit_df$Perceived_Risk_Sum)
```

## Demographics ##  

```{r}
## number of included participants
#study requested 400 participants: 
#original df dataset had 444 rows, removed 62 rows in Load and Cleanup Data section (unneeded rows, DoG/pandemic outliers, incomplete trials, and too short or too long entries) = 388 rows 
#omit_df dataset had 388 rows, removed 6 entries with missing data 

nrow(omit_df) # 382 rows

#duration, demographics
mean(df$Duration..in.seconds., na.rm = TRUE)
mean(omit_df$Duration..in.seconds.)
sd(omit_df$Duration..in.seconds.)

summary(omit_df$Age)
table(omit_df$Gender)
table(omit_df$Race)
table(omit_df$Education)
```

```{r}
#Age
hist(omit_df$Age)

#Gender
# 1) create new variable with gender recoded as a factor
omit_df$GenderasFactor <- factor(omit_df$Gender, levels=1:8, labels=c("male", "female", "non-binary", "other", "prefer not to answer", "trans man", "trans woman", "genderqueer"))
# 2) create barplot with new Gender variable
ggplot(omit_df) +
  geom_bar(aes(x = GenderasFactor)) +
  ggtitle("Count of Gender") +
  theme(plot.title = element_text(hjust = 0.5))

#Education
omit_df$EducationasFactor <- factor(omit_df$Education, levels=1:6, labels=c("Unknown","No hs diploma","No college","Some college","4 yr college","Graduate degree"))
ggplot(omit_df) +
  geom_bar(aes(x = EducationasFactor)) +
  ggtitle("Count of Education") +
  theme(plot.title = element_text(hjust = 0.5))

#Race
omit_df$RaceasFactor <- factor(omit_df$Race, levels=1:7, labels=c("Am Indian","Asian","Pacific Islander","Black","White","Multiple","Unknown"))
ggplot(omit_df) +
  geom_bar(aes(x = RaceasFactor)) +
  ggtitle("Count of Race") +
  theme(plot.title = element_text(hjust = 0.5))

# Relations between variables
#ggplot(data = omit_df) + 
  #geom_point(mapping = aes(x = COVID_DoG_Sum, y = Perceived_Risk_Sum))

```

## Preliminary Analyses/ Correlations 
```{r}
# COVID DoG index and Expextation of Pandemic Length
ggscatter(omit_df, x = "COVID_DoG_index", y = "PandemicLengthExpect.1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Partipcants'Average COVID Delay of Gratification ", ylab = "Partipcants'Expextation of Pandemic Length")
# Traveling index and social gatherings index
ggscatter(omit_df, x = "traveling_index", y = "socialgatherings_index", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "traveling index ", ylab = "social gathering index")
# COVID DoG index and impact
ggscatter(omit_df, x = "COVID_DoG_index", y = "Impacts_index", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Partipcants'Average COVID Delay of Gratification ", ylab = "Partipcants' average impact from COVID19")

# COVID DoG index and Experiences
ggscatter(omit_df, x = "COVID_DoG_index", y = "Experiences_index", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Partipcants'Average COVID Delay of Gratification ", ylab = "Partipcants' average expereince from COVID19")

# COVID DoG index and stress_index
ggscatter(omit_df, x = "COVID_DoG_index", y = "Stress_index", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Partipcants' Average COVID Delay of Gratification ", ylab = "Partipcants' average stress about COVID19")

```

## Task Analyses 
# COVID DoG and Perceived Risk/Value
```{r}
hist(omit_df$socialgatherings_index)
summary(omit_df$socialgatherings_index)
hist(omit_df$traveling_index)
summary(omit_df$traveling_index)

#Question: are there data driven differences between the two indices (social gatherings and traveling)? E.g. days in one versus months in other
socialgatherings_units <- omit_df %>% select(COVID_DoG_Questions.2_1:COVID_DoG_Questions.2_3)
summary(rowMeans(socialgatherings_units))
traveling_units <- omit_df %>% select(COVID_DoG_Questions.2_4:COVID_DoG_Questions.2_6)
summary(rowMeans(traveling_units))
#Answer: it doesn't look like there's differences between the units for two categories, both have similar means? (2.608 v. 3.094) - rounds to 3, thus the average unit response for both indices was months

#perform EFA to see if there are two separate factors for DoG that pertain to travel and social situations/gatherings that influence how participants respond? This would answer the question to whatever or not we should keep the things separate or together
#EFA steps:
##basic factor analysis model: y = (lambda)(f) + (u) 
#y = individual's score on observed variable
#lambda = factor loading indicating relation between observed variable and latent common factor
#f = individual's score on latent common factor
#u = individual's score on latent unique factor

# Future plans:
#index: Expectation of Pandemic; May help us evaluate how folks expectations relate to their DoG index + that relationship may be meaningful across other analyses
#perform tests with other variables (e.g. general uncertainty) 3 times:
#1) DoG Index by itself
#2) Index:Expectation of Pandemic
#3) Both indices
```

# COVID DoG and General Uncertainty
```{r}
# normality assumption
shapiro.test(omit_df$GCS_Sum)  #pvalue = 0.011 (>.05), yes normally distributed

```

## Linear Regressions
#Moral Foundations and Delaying
```{r}

MFTModel <- lm(COVID_DoG_index ~ harm_foundation + fairness_foundation + authority_foundation + ingroup_foundation +purity_foundation, data = omit_df)
               
summary(MFTModel) 

```
#Disgust and delaying 
```{r}

DisgustModel <- lm(COVID_DoG_index ~ Pathogen_Disgust_index + Moral_Disgust_index + Sexual_Disgust_index, data = omit_df)
               
summary(DisgustModel) 

```

#Norms, Stress, and Delaying
```{r}

COVIDDoG.norms.lm <- lm(COVID_DoG_index ~ Norms_index + Stress_index, data = omit_df)

summary(COVIDDoG.norms.lm)


```

# MISC SECTION #

## Exploratory Factor Analysis for COVID DoG
# Creates csv of the df dataset AND csv with just the 6 questions (using transformed data with units in days) of COVID_DoG
# Used by Winnie to do EFA separately, see EFA_Analysis Doc in 3C repo
```{r}
write.csv(df, 'df.csv')
COVID_DoG <- data.frame(df$COVID_DoG_Questions.1,df$COVID_DoG_Questions.2,df$COVID_DoG_Questions.3,df$COVID_DoG_Questions.4, df$COVID_DoG_Questions.5, df$COVID_DoG_Questions.6)
COVID_DoG
write.csv(COVID_DoG, 'COVID_DoG.csv')
```